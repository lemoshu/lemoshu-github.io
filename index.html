<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" type="image/x-icon" href="./pic/favicon2.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Zhe Xu, Xu Zhe, CUHK, The Chinese University of Hong Kong, Harvard"> 
<meta name="description" content="Jack's Party">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Zhe Xu@CUHK</title>
</head>
<body>
<div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/lemoshu" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Zhe (Jack) Xu </h1><h1>
				</h1></div>

				<h3>Ph.D. Candidate</h3>
				<p>
					Massachusetts General Hospital, Harvard Medical School & <br>
					The Chinese University of Hong Kong <br>
					Now: Boston, MA, USA<br>
					
					<br>
					Email: jackxz [at] link.cuhk.edu.hk; zxu8 [at] bwh.harvard.edu<br>
					
				</p>
				<p> <a href="https://scholar.google.com/citations?hl=en&user=K-EoeRgAAAAJ"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.linkedin.com/in/lemoshu/"><img src="./pic/LinkedIn.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/lemoshu"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
					<!-- <a href="https://space.bilibili.com/399165010"><img src="./pic/bilibili.jpg" height="30px" style="margin-bottom:-3px"></a> -->
				</p>
			</td>
			<td>
				<img src="./pic/xz.png" border="0" width="200"><br>
				<p style="text-align:center; font-size: smaller;">
				  @Boston, ðŸ‡ºðŸ‡¸
				</p>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography</h2>
<p>
	I am a final-year Ph.D. candidate at <a href="https://www.cuhk.edu.hk/english/aboutus/message.html">The Chinese University of Hong Kong</a>, supervised by <a href="https://scholar.google.com/citations?user=agHXXD4AAAAJ" target="_blank">Prof. Raymond Tong</a> (AIMBE Fellow). I am also co-trained at <a href="https://camca.mgh.harvard.edu/">CAMCA</a>, Massachusetts General Hospital, Harvard Medical School, supervised by <a href="https://scholar.google.com/citations?user=MHq2z7oAAAAJ&hl=en">Prof. Quanzheng Li</a>. I obtained my M.S. in Computer Science at <a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a> in 2021, supervised by <a href="https://thusigsclub.github.io/thu.github.io/" target="_blank">Prof. Xiu Li</a> (joint training at <a href="https://spl.harvard.edu/" target="_blank">SPL</a>, Brigham and Women's Hospital, <a href="https://hms.harvard.edu/" target="_blank">Harvard Medical School</a>, working closely with <a href="https://scholar.google.com/citations?user=i3Blz1UAAAAJ" target="_blank">Prof. Jayender Jagadeesan</a>, <a href="https://scholar.google.com/citations?user=DwXLsT8AAAAJ">Prof. Sandy Wells</a>), and B.Eng in Electronic Engineering and B.Sc in Management from <a href="https://en.uestc.edu.cn/">UESTC</a> in 2018. I also work closely with <a href="https://jarvislab.tencent.com/index-en.html">Tencent Youtu Jarvis Center</a> led by <a href="https://scholar.google.com/citations?hl=en&user=vAIECxgAAAAJ" target="_blank">Dr. Yefeng Zheng</a> (IEEE Fellow) since 2020. I'm a recipient of the <a href="https://cerg1.ugc.edu.hk/hkpfs/index.html" target="_blank">Hong Kong PhD Fellowship (HKPFS)</a>.
</p>
<p>My research lies at advancing medical image analysis with AI to achieve affordable-yet-accurate medical decision-making, with recent focus on 1) learning under various imperfect data scenarios (e.g., label/data scarcity, noise and heterogeneity), 2) multimodal data supported representation learning and decision making, 3) data-centric, human-in-the-loop, continual learning for generalizable real-world agents, 4) generative AI for brain decoding and medical data enhancement.</p>

<!-- Clinically practical, safe, interpretable, simple-yet-effective methods are favored -->


<h2>News</h2>
<div style="height: 240px; overflow: auto;">
<ul>
	<li>
		[07/2024] Scalable Multi-modal Medical Agent (MMedAgent) is <a href="https://arxiv.org/pdf/2407.02483">online</a>!
	</li>
	<li>
		[06/2024] 2 papers on label-efficient and foundation model were accepted by MICCAI 2024. See you in Morocco!
	</li>
	<li>
		[02/2024] <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_Diversified_and_Personalized_Multi-rater_Medical_Image_Segmentation_CVPR_2024_paper.pdf">D-Persona</a> on multi-rater segmentation accepted by CVPR 2024 with Highlight (2.8%)! Congrats to <a href="https://ycwu1997.github.io/eli/">Yicheng</a>!
	</li>
	<li>
		[02/2024] Our <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231224001450">trustworthy radiology report generation</a> accepted by Neurocomputing (IF=6.0)! Congrats to <a href="https://www.yyixinwang.com/">Yixin</a>!
	</li>
	<li>
		[01/2024] Our <a href="https://www.sciencedirect.com/science/article/pii/S1361841524000203">SCL</a> for MS-SSL was accepted by Medical Image Analysis (IF=10.9)! 
	</li>
	<li>
		[12/2023] Moved to Boston, USA and joined <a href="https://camca.mgh.harvard.edu/">CAMCA</a>, MGH/Harvard Medical School as a visiting PhD student!
	</li>
<!--
	<li>
        [11/2023] 1 joint paper on unsupervised ML-based new cancer cachexia subtype discovery accepted by Nutrition!
	</li>
-->
	<li>
		[10/2023] Glad to be awarded as a IEEE TMI Distinguished Reviewer (Gold Level)!
	</li>
	<li>
		[10/2023] Glad to be in MICCAI'23 Best Paper and Young Scientist Award finalist (Top 25 out of 730 accepted papers)!
	</li>
	<li>
		[07/2023] Glad to receive <a href="https://conferences.miccai.org/2023/en/MICCAI-2023-STudent-Author-Registration-(STAR)-Awards.html">MICCAI STAR Award</a> (aka. Travel Award)!
	</li>
	<li>
		[06/2023] Our <a href="https://ieeexplore.ieee.org/document/9779756">MTCL</a> is part of tutorial in <a href="https://collab.dvb.bayern/display/TUMdlma/DLMA%3A+Summer+2023">DLMAâ€˜23</a> summer camp of TUM (hosted by Prof. Nassir Navab)!
	</li>
	<li>
		[06/2023] Our <a href="https://www.sciencedirect.com/science/article/pii/S1361841523001408">AC-MT</a> for SSL was accepted by Medical Image Analysis (IF=10.9)! 
	</li>
	<li>
		[06/2023] 4 papers on label-efficient/multimodal learning accepted by <a href="https://conferences.miccai.org/2023/en/">MICCAI 2023</a> (2 early accept(14%), 1 oral(3%))! 
	</li>
	<li>
		[05/2023] 1 mentoring paper on SFUDA was accepted by Computers in Biology and Medicine (IF=7.7)! 
	</li>
	<li>
		[03/2023] 1 paper on SSL accepted by EMBC 2023 (oral)! 
	</li>
	<li>
		[02/2023] <a href="https://link.springer.com/chapter/10.1007/978-3-031-34048-2_52">ProtoSeg</a> on active histopathology analysis was accepted by <a href="https://www.ipmi2023.org/en">IPMI 2023</a> (oral)! Congrats to <a href="https://yjump.github.io/">Jiangpeng</a>,<a href="https://winterpan2017.github.io/">Wentao</a>!
	</li>
	<li>
		[10/2022] 1 joint paper <a href="https://ieeexplore.ieee.org/document/9925717">Learn2Reg</a> on DL-oriented multi-task image registration benchmark was accepted by IEEE TMI!  
	</li>
	<li>
		[09/2022] Attending <a href="https://conferences.miccai.org/2022/en/">MICCAIâ€™22</a> in Singapore! Welcome to catch up:)
	</li>
	<li>
		[07/2022] Passed the qualified exam towards a PhD candidate! 
	</li>
	<li>
		[06/2022] 2 joint papers on <a href="https://link.springer.com/chapter/10.1007/978-3-031-16446-0_14">image registration</a> and <a href="https://link.springer.com/chapter/10.1007/978-3-031-16446-0_4">landmark error screening</a> were accepted by MICCAI 2022 (~31%)! 
	</li>
	<li>
		[05/2022] Awarded Talent Development Scholarship on Innovation, science and technology from HK Gov! 
	</li>
	<li>
		[05/2022] Our <a href="https://ieeexplore.ieee.org/document/9779756">MTCL</a> for learning segmentation with noisy labels was accepted by IEEE TMI (IF=11.037)!
	</li>
	<li>
		[05/2022] 2 papers on <a href="https://link.springer.com/chapter/10.1007/978-3-031-16446-0_2">image registration</a> and <a href="https://link.springer.com/chapter/10.1007/978-3-031-16443-9_21">SFUDA</a> early accepted by MICCAI 2022 (Top 13%)!
	</li>
	<li>
		[03/2022] Our <a href="https://ieeexplore.ieee.org/document/9741294">CPCL</a>, a supervised-like semi-supervised segmentation, was accepted by IEEE J-BHI!
	</li>
	<li>
		[01/2022] 1 paper on cross-domain few-shot learning accepted by ICASSP 2022. Congrats to <a href="https://www.yyixinwang.com/">Yixin</a>!
	</li>
	<li>
		[09/2021] Invited to give oral presentation at MICCAI Learn2Reg and contribute to the <a href="https://arxiv.org/pdf/2112.04489.pdf">Challenge paper</a>.
	</li>
	
	<li>
		[06/2021] Awarded as Outstanding Graduate of Beijing; Thank you, THU and Harvard! Moving to Hong Kong!
	</li>
	
	<li>
		[05/2021] 2 papers on noisy-label segmentation and WSI segmentation early accepted by MICCAI 2021 (Top 13%)!
	</li>
	
	<li>
		[04/2021] Glad to be Hong Kong PhD Fellowship (HKPFS) Awardee
	</li>
	
	<li>
		[01/2021] 3 papers on image registration accepted by ISBI 2021, ICASSP 2021, and IJCARS
	</li>
	
	<li>
		[10/2020] Awarded National Scholarship (for postgraduate) at Tsinghua
	</li>
	
	<li>
		[06/2020] 1 paper on synthesis-based multimodal registration accepted by MICCAI 2020!
	</li>
	
	<li>
		[09/2019] Moved to Boston, USA and joined SPL of Harvard
	</li>
	
	<li>
		[06/2019] Our startup "CloudSpace: AI+design" won a Gold Award in the Greater Bay Area Entrepreneurship Competition
	</li>
</ul>
</div>


<h2> Selected Publications | <a href="https://scholar.google.com/citations?hl=en&user=K-EoeRgAAAAJ">Full List</a></h2>
<!--
<div style="height: 1440px; overflow: auto;">
-->
<table id="tbPublications" width="100%">
	<tbody>
	<td><b>/*Journal*/</b>
	<p></p>
	</td>
	<tr>
		<td width="306">
		<img src="./indexpics/2024-MIA-SCL.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Separated Collaborative Learning for Semi-supervised Prostate Segmentation with Multi-site Heterogeneous Unlabeled MRI Data</b></p>
		<p><b>Zhe Xu</b>, Donghuan Lu, Jie Luo, Yefeng Zheng, Raymond Tong</p>
		<em>Medical Image Analysis (<b>MedIA</b>), 2024. </em><br />
		<i><p style="color: red; display: inline;">(IF: 10.9, JCR-Q1)</p></i> [<a href="https://www.sciencedirect.com/science/article/pii/S1361841524000203">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		
	
	<tr>
		<td width="306">
		<img src="./indexpics/2023-ACMT.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Ambiguity-selective Consistency Regularization for Mean-Teacher Semi-supervised Medical Image Segmentation</b></p>
		<p><b>Zhe Xu</b>, <a href="https://www.yyixinwang.com/">Yixin Wang</a>, Donghuan Lu, <a href="https://luoxd1996.github.io/">Xiangde Luo</a>, <a href="https://yjump.github.io/">Jiangpeng Yan</a>, Yefeng Zheng, Raymond Tong</p>
		<em>Medical Image Analysis (<b>MedIA</b>), 2023. </em><br />
		<i><p style="color: red; display: inline;">(IF: 10.9, JCR-Q1)</p></i> [<a href="https://www.sciencedirect.com/science/article/pii/S1361841523001408">paper</a>, <a href="https://github.com/lemoshu/AC-MT">code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

	
	<tr>
		<td width="306">
		<img src="./indexpics/2022-MTCL-TMI.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Anti-interference from Noisy Labels: Mean-Teacher-assisted Confident Learning for Medical Image Segmentation</b></p>
		<p><b>Zhe Xu</b>, Donghuan Lu, Jie Luo, Yixin Wang, Jiangpeng Yan, Kai Ma, Yefeng Zheng, Raymond Tong</p>
		<em>IEEE Transactions on Medical Imaging (<b>TMI</b>), 2022. </em><br />
		<i><p style="color: red; display: inline;">(IF: 11.037, JCR-Q1)</p></i> [<a href="https://ieeexplore.ieee.org/document/9779756">paper</a>, <a href="https://github.com/lemoshu/MTCL">code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		
	<tr>
		<td width="306">
		<img src="./indexpics/2021-CPCL.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>All-Around Real Label Supervision: Cyclic Prototype Consistency Learning for Semi-supervised Medical Image Segmentation</b></p>
		<p><b>Zhe Xu</b>, <a href="https://www.yyixinwang.com/">Yixin Wang</a>, Donghuan Lu, <a href="https://yulequan.github.io/">Lequan Yu</a>, <a href="https://yjump.github.io/">Jiangpeng Yan</a>, Jie Luo, Kai Ma, Yefeng Zheng, Raymond Kai-yu Tong</p>
		<em>IEEE Journal of Biomedical and Health Informatics (<b>J-BHI</b>), 2022. </em><br />
		<i><p style="color: red; display: inline;">(IF: 7.021, JCR-Q1)</p></i> [<a href="https://ieeexplore.ieee.org/document/9741294">paper</a>, <a href="https://github.com/lemoshu/CPCL">code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="./indexpics/2022-RGen.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Trust It or Not: Confidence-Guided Automatic Radiology Report Generation</b></p>
		<p>Yixin Wang*, Zihao Lin*, <b>Zhe Xu</b>, Haoyu Dong, Jiang Tian, Jie Luo, Zhongchao Shi, Lifu Huang, Yang Zhang, Jianping Fan, Zhiqiang He. (* equal contribution)</p>
		<em>Neurocomputing, 2024. </em><br />
		<i><p style="color: red; display: inline;">(IF: 6.0, JCR-Q1)</p></i> [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231224001450">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="./indexpics/2022-Learn2Reg.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Learn2Reg: comprehensive multi-task medical image registration challenge, dataset and evaluation in the era of deep learning</b></p>
		<p>Wentao Pan, <b>Zhe Xu</b> (<a href="https://github.com/WinterPan2017/ADLReg">ADLReg</a> | THU Team)</p>
		<p><div style="height: 38px; overflow: auto;">
		 <font size="1"><b><em>Full Author List</em></b>: Alessa Hering, Lasse Hansen, Tony C. W. Mok, Albert C. S. Chung, Hanna Siebert, Stephanie HÃ¤ger, Annkristin Lange, Sven Kuckertz, Stefan Heldmann, Wei Shao, Sulaiman Vesal, Mirabela Rusu, Geoffrey Sonn, ThÃ©o Estienne, Maria Vakalopoulou, Luyi Han, Yunzhi Huang, Pew-Thian Yap, Mikael Brudfors, YaÃ«l Balbastre, Samuel Joutard, Marc Modat, Gal Lifshitz, Dan Raviv, Jinxin Lv, Qiang Li, Vincent Jaouen, Dimitris Visvikis, Constance Fourcade, Mathieu Rubeaux, Wentao Pan, <b>Zhe Xu</b>, Bailiang Jian, Francesca De Benetti, Marek Wodzinski, Niklas Gunnarsson, Jens SjÃ¶lund, Daniel Grzech, Huaqi Qiu, Zeju Li, Alexander Thorley, Jinming Duan, Christoph GroÃŸbrÃ¶hmer, Andrew Hoopes, Ingerid Reinertsen, Yiming Xiao, Bennett Landman, Yuankai Huo, Keelin Murphy, Nikolas Lessmann, Bram van Ginneken, Adrian V. Dalca, Mattias P. Heinrich</font>
		</div></p>
		<em>IEEE Transactions on Medical Imaging (<b>TMI</b>), 2022. </em><br />
		<i><p style="color: red; display: inline;">(IF: 11.037, JCR-Q1)</p></i> [<a href="https://ieeexplore.ieee.org/document/9925717">paper</a>, <a href="https://learn2reg.grand-challenge.org/Learn2Reg2021/">page</a>, <a href="https://github.com/WinterPan2017/ADLReg">our code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>		
<!--
	<tr>
		<td width="306">
		<img src="./indexpics/2021-ijcars-f3rnet.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>F3RNet: full-resolution residual registration network for deformable image registration</b></p>
		<p><b>Zhe Xu</b>, Jie Luo, Jiangpeng Yan, Xiu Li, Jagadeesan Jayender</p>
		<em>International Journal of Computer Assisted Radiology and Surgery (<b>IJCARS</b>), 2021. </em><br />
		<i><p style="color: red; display: inline;">(IF: 3.421, JCR-Q1)</p></i> [<a href="https://link.springer.com/article/10.1007/s11548-021-02359-4">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		

	<tr>
		<td width="306">
		<img src="./indexpics/2020-regis-survey.png" width="285px" style="box-shadow: 4px 4px 8px #888">	
		</td>
		<td>
		<p><b>A Survey on Deep Learning-based Medical Image Registration (in Chinese)</b></p>
		<p>Lufan Ma, Feng Luo, Jiangpeng Yan, <b>Zhe Xu</b>, Jie Luo, Xiu Li.</p> 
		<em>ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ (Journal of Image and Graphics), 2021. </em>[<a href="http://www.cjig.cn/jig/ch/reader/view_abstract.aspx?file_no=20210901">paper</a>] 
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
-->		
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		
	<td><b>/*Conference*/</b>
	<p></p>
	</td>
	<tr>
		<td width="306">
		<img src="./indexpics/2024-CVPR-Wu.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Diversified and Personalized Multi-rater Medical Image Segmentation</b></p>
		<p> Yicheng Wu*, Xiangde Luo*, <b>Zhe Xu</b>, Xiaoqing Guo, Lie Ju, Zongyuan Ge, Wenjun Liao, and Jianfei Cai</p>
		<em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024. </em><br />
		<i><p style="color: red; display: inline;">(Highlight)</p></i> [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_Diversified_and_Personalized_Multi-rater_Medical_Image_Segmentation_CVPR_2024_paper.pdf">paper</a>, <a href="https://github.com/ycwu1997/D-Persona">code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>


	<tr>
		<td width="306">
		<img src="./indexpics/2023-MICCAI-CU2L.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data</b></p>
		<p> <b>Zhe Xu</b>, Donghuan Lu, Jiangpeng Yan, Jinghan Sun, Jie Luo, Dong Wei, Sarah Frisken, Quanzheng Li, Yefeng Zheng, Raymond Tong</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2023. </em><br />
		<i><p style="color: red; display: inline;">(Oral, early accept)</p></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-031-43901-8_1">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="./indexpics/2023-MICCAI-PLIL.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Towards Expert-Amateur Collaboration: Prototypical Label Isolation Learning for Left Atrium Segmentation with Mixed-Quality Labels</b></p>
		<p> <b>Zhe Xu</b>, Jiangpeng Yan, Donghuan Lu, Yixin Wang, Jie Luo, Yefeng Zheng, Raymond Tong</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2023. </em><br />
		[<a href="https://link.springer.com/chapter/10.1007/978-3-031-43990-2_10">paper</a>, <a href="https://github.com/lemoshu/PLIL">code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		
	<tr>
		<td width="306">
		<img src="./indexpics/2023-MICCAI-report.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>You've Got Two Teachers: Co-evolutionary Image and Report Distillation for Semi-supervised Anatomical Abnormality Detection in Chest X-ray</b></p>
		<p> <a href="https://jinghansunn.github.io/jhsun.github.io/">Jinghan Sun</a>*, Dong Wei*, <b>Zhe Xu</b>, Donghuan Lu, Hong Liu, Liansheng Wang, Yefeng Zheng (* equal contribution)</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2023. </em><br />
		<i><p style="color: red; display: inline;">(early accept)</p></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-031-43907-0_35">paper</a>, <a href="https://github.com/jinghanSunn/CoE-DG">code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="./indexpics/2023-MICCAI-SCNet.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Weakly Supervised Medical Image Segmentation via Superpixel-guided Scribble Walking and Class-wise Contrastive Regularization</b></p>
		<p> Meng Zhou*, <b>Zhe Xu</b>*^, <a href="https://zhoukang.pro/">Kang Zhou</a>, Raymond Tong^ (^corresponding)</p> 
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2023. </em><br />
		[<a href="https://link.springer.com/chapter/10.1007/978-3-031-43895-0_13">paper</a>, <a href="https://github.com/Lemonzhoumeng/SC-Net">code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		
	<tr>
		<td width="306">
		<img src="./indexpics/2022-ProtoSeg.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Human-machine Interactive Tissue Prototype Learning for Label-efficient Histopathology Image Segmentation</b></p>
		<p>Wentao Pan*, Jiangpeng Yan*, Hanbo Chen*, Jiawei Yang, <b>Zhe Xu</b>, Xiu Li, Jianhua Yao (* equal contribution)</p>
		<em>Information Processing in Medical Imaging (<b>IPMI</b>), 2023. </em><br />
		<i><a href="https://www.ipmi2023.org/files/downloads/IPMI2023-Program.pdf"><p style="color: red; display: inline;">(Oral)</p></a></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-031-34048-2_52">paper</a>, <a href="https://github.com/WinterPan2017/proto2seg">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		
	<tr>
		<td width="306">
		<img src="./indexpics/2022-adaptiveregis.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Double-Uncertainty Guided Spatial and Temporal Consistency Regularization Weighting for Learning-based Abdominal Registration</b></p>
		<p><b>Zhe Xu</b>, Jie Luo, Donghuan Lu, Jiangpeng Yan, Sarah Frisken, Jayender Jagadeesan, William Wells III, Xiu Li, Yefeng Zheng, Raymond Tong</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2022. </em><br />
		<i><p style="color: red; display: inline;">(early accept)</p></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-031-16446-0_2">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		
	<tr>
		<td width="306">
		<img src="./indexpics/2022-miccai-D4R.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Denoising for Relaxing: Unsupervised Domain Adaptive Fundus Image Segmentation without Source Data</b></p>
		<p><b>Zhe Xu</b>, Donghuan Lu, Yixin Wang, Jie Luo, Dong Wei, Yefeng Zheng, Raymond Tong</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2022. </em><br />
		<i><p style="color: red; display: inline;">(early accept)</p></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-031-16443-9_21">paper</a>][Extended application of our MTCL (MICCAI'21)]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		
<!--
	<tr>
		<td width="306">
		<img src="./indexpics/2022-miccai-deformer.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Deformer: Towards Displacement Field Learning for Unsupervised Medical Image Registration</b></p>
		<p>Jiashun Chen, Donghuan Lu, Dong Wei, Munan Ning, Xinyu Shi, <b>Zhe Xu</b>, Yefeng Zheng, Yu Zhang.</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2022. </em> <br />
		[<a href="https://link.springer.com/chapter/10.1007/978-3-031-16446-0_14">paper</a>, <a href="https://static-content.springer.com/esm/chp%3A10.1007%2F978-3-031-16446-0_14/MediaObjects/539249_1_En_14_MOESM1_ESM.pdf">supp</a>, <a href="https://github.com/CJSOrange/DMR-Deformer">code</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
-->
<!--
	<tr>
		<td width="306">
		<img src="./indexpics/2020-arxiv-dataset.png" width="285px" style="box-shadow: 4px 4px 8px #888">	
		</td>
		<td>
		<p><b>On the Dataset Quality Control for Image Registration Evaluation</b></p>
		<p>Jie Luo, Guangshen Ma, Nazim Haouchine, <b>Zhe Xu</b>, Parikshit Juvekar, Yixin Wang, Yiming Xiao, Alexandra Golby, Patrick Codd, William Wells, Sarah Frisken.</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2022. </em><br />
		[<a href="https://link.springer.com/chapter/10.1007/978-3-031-16446-0_4">paper</a>]
		</td>
	</tr>
-->

	<tr>
		<td width="306">
		<img src="./indexpics/2021-miccai-MTCL.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Noisy Labels are Treasure: Mean-Teacher-assisted Confident Learning for Hepatic Vessel Segmentation</b></p>
		<p><b>Zhe Xu</b>, Donghuan Lu, Yixin Wang, Jie Luo, Jayender Jagadeesan, Kai Ma, Yefeng Zheng, Xiu Li</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2021. </em><br />
		<i><p style="color: red; display: inline;">(early accept)</p></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-030-87193-2_1">paper</a>, <a href="https://github.com/lemoshu/MTCL">code</a>][Part of tutorial for <a href="https://collab.dvb.bayern/display/TUMdlma/DLMA%3A+Summer+2023">DLMA</a> at TUM]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

<!-- 	<tr>
		<td width="306">
		<img src="./indexpics/2021-miccai-yjpWSI.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Hierarchical Attention Guided Framework for Multi-resolution Collaborative Whole Slide Image Segmentation</b></p>
		<p><a href="https://yjump.github.io/">Jiangpeng Yan</a>, Hanbo Chen, Kang Wang, Yan Ji, Yuyao Zhu, Jingjing Li, Dong Xie, <b>Zhe Xu</b>, Junzhou Huang, Shuqun Cheng, Xiu Li, Jianhua Yao.</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2021. </em><br />
		<i><p style="color: red; display: inline;">(early accept)</p></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-030-87237-3_15">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr> -->

<!-- 	<tr>
		<td width="306">
		<img src="./indexpics/2021-icassp-gradient.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Unsupervised Multimodal Image Registration with Adaptative Gradient Guidance</b></p>
		<p><b>Zhe Xu</b>, Jiangpeng Yan, Jie Luo, Xiu Li, Jayender Jagadeesan.</p>
		<em>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2021. </em>[<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414320">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>	 -->

	<tr>
		<td width="306">
		<img src="./indexpics/2020-miccai-Advdual.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td>
		<p><b>Adversarial Uni-and Multi-modal Stream Networks for Multimodal Image Registration</b></p>
		<p><b>Zhe Xu</b>, Jie Luo, Jiangpeng Yan, Ritvik Pulya, Xiu Li, William Wells III, Jayender Jagadeesan.</p>
		<em>Medical Image Computing and Computer Assisted Interventions (<b>MICCAI</b>), 2020.</em><br />
		<i><p style="color: red; display: inline;">(Oral)</p></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-030-59716-0_22">paper</a>] [Nice Follow-up: <a href="https://www.sciencedirect.com/science/article/pii/S1361841521003376">MedIA@JHU</a>, <a href="https://ieeexplore.ieee.org/abstract/document/9665765">DDMReg(TMI)@Harvard</a>]
		</td>
		
	</tr>
	<tr>&nbsp</tr>		
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
	
		
<!--		
	<tr>
		<td width="306">
		<img src="./indexpics/2022-icassp-fewshot.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Cross-domain Few-shot Learning for Rare-Disease Skin Lesion Segmentation</b></p>
		<p><a href="https://www.yyixinwang.com/">Yixin Wang</a>, <b>Zhe Xu</b>, Jiang Tian, Jie Luo, Zhongchao Shi, Yang Zhang, Jianping Fan, Zhiqiang He.</p>
		<em>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2022. </em>[<a href="https://ieeexplore.ieee.org/document/9746791">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
-->		

<!--
	<tr>
		<td width="306">
		<img src="./indexpics/2021-isbi-cyclic.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Unimodal Cyclic Regularization For Training Multimodal Image Registration Networks</b></p>
		<p><b>Zhe Xu</b>, Jiangpeng Yan, Jie Luo, William Wells, Xiu Li, Jayender Jagadeesan.</p>
		<em>IEEE 18th International Symposium on Biomedical Imaging (<b>ISBI</b>), 2021. </em>
		<i><p style="color: red; display: inline;">(Oral)</p></i> [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9433926">paper</a>]
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>		
-->

<!--
	<tr>
		<td width="306">
		<img src="./indexpics/2021-iconip.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Towards Better Dermoscopic Image Feature Representation Learning for Melanoma Classification</b></p>
		<p>Chenghui Yu, Mingkang Tang, Shengge Yang, Mingqing Wang, <b>Zhe Xu</b>, Jiangpeng Yan, Hanmo Chen, Yu Yang, Xiao-Jun Zeng and Xiu Li	</p>
		<em>International Conference on Neural Information Processing (<b>ICONIP</b>), 2021. </em> 
		<i><p style="color: red; display: inline;">(Oral)</p></i> [<a href="https://link.springer.com/chapter/10.1007/978-3-030-92273-3_45">paper</a>]
		</td>
-->
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

	<td><b>/*Preprint*/</b>
	<p></p>
	</td>

	<tr>
		<td width="306">
		<img src="./indexpics/2024-MMedAgent.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>MMedAgent: Learning to Use Medical Tools with Multi-modal Agent</b></p>
		<p>Binxu Li, Tiankai Yan, Yuanting Pan, <b>Zhe Xu</b>, Jie Luo, Ruiyang Ji, Shilong Liu, Haoyu Dong, Zihao Lin, Yixin Wang</p>
		<em>Under Review, 2024. </em>[<a href="https://arxiv.org/pdf/2407.02483">paper</a>, <a href=" ">code</a>, Recs.: <a href="https://github.com/tmgthb/Autonomous-Agents/">Autonomous Agents</a>, <a href="https://github.com/quchangle1/LLM-Tool-Survey">Tool Learning</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="./indexpics/2023-MaskMatch.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Semi-supervised Semantic Segmentation Meets Masked Modeling: Fine-grained Locality Learning Matters in Consistency Regularization</b></p>
		<p>Weitao Pan, <b>Zhe Xu</b>, Jiangpeng Yan, Zihan Wu, Raymond Tong, Jianhua Yao.</p>
		<em>Under Review, 2023. </em>[<a href="https://arxiv.org/pdf/2312.08631.pdf">paper</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
	
	<tr>
		<td width="306">
		<img src="./indexpics/2023-TMI-report.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Unlocking the Potential of Weakly Labeled Data: A Co-Evolutionary Learning Framework for Abnormality Detection and Report Generation</b></p>
		<p>Jinghan Sun*, Dong Wei*, <b>Zhe Xu</b>, Donghuan Lu, Hong Liu, Hong Wang, Liansheng Wang, Yefeng Zheng. (* equal contribution)</p>
		<em>Major Revision in IEEE TMI, 2023. </em>[<a href=" ">paper</a>, <a href="https://github.com/jinghanSunn/CoE-DG">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="./indexpics/2022-reconstruct.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Seeking Common Ground While Reserving Differences: Multiple Anatomy Collaborative Framework for Undersampled MRI Reconstruction</b></p>
		<p>Jiangpeng Yan, Chenghui Yu, Hanbo Chen, <b>Zhe Xu</b>, Junzhou Huang, Xiu Li, Jianhua Yao. </p>
		<em>Under Review in MedIA, 2023. </em>[<a href="https://arxiv.org/pdf/2206.07364.pdf">paper</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>		

</tbody></table>
<!--
</div>
-->




<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">
	<tbody>
	<tr><td> 2024, Reaching Out Award (HKSAR Gov Fund)</td></tr>
	<tr><td> 2024, Overseas Research Attachment Programme (CUHK Engineering)</td></tr>
	<tr><td> 2023, IEEE TMI Distinguished Reviewer (Gold Level)</td></tr>
	<tr><td> 2023, MICCAI Best Paper and Young Scientist Award Finalist</td></tr>
	<tr><td> 2023, <a href="https://conferences.miccai.org/2023/en/MICCAI-2023-STudent-Author-Registration-(STAR)-Awards.html">MICCAI STudent-Author Registration (STAR) Award</a></td></tr>
	<tr><td> 2022, Hong Kong,China-Asia-Pacific Economic Cooperation Scholarship (<a href="https://education.apec.org/hong-kong.html" target="_blank">APEC Scholarship.</a>)</td></tr>
	<tr><td> 2022, Talent Development Scholarship on Innovation, science and technology (<a href="https://www.edb.gov.hk/en/edu-system/postsecondary/local-higher-edu/publicly-funded-programmmes/scholarship.html" target="_blank">HKSAR Gov.</a>)</td></tr>
	<tr><td> 2021-2025, <a href="https://cerg1.ugc.edu.hk/hkpfs/index.html" target="_blank">Hong Kong PhD Fellowship (HKPFS)</a> & CUHK Vice-Chancellorâ€™s Scholarship</td></tr>
	<tr><td> 2021, Outstanding Graduate of Beijing</td></tr>
	<tr><td> 2016/2020, China National Scholarship (for undergraduate / postgraduate)</td></tr>
	<tr><td> 2019, Gold Prize of Guangdong-HK-Macao Greater Bay Area College Social Entrepreneurship Challenge</td></tr>
	<tr><td> 2017, Silver Award in National Entrepreneurship Competition for college students</td></tr>
	<tr><td> 2016, First Prize of China Undergraduate Mathematical Contest in Modeling (CUMCM)</td></tr>
	</tbody>
</table>

<h2>Professional Services</h2>
<ul>
	<li>	
	<b>Regular Reviewers/PC Member:</b><br>
	Computer Vision and Pattern Recognition (CVPR)<br>
	International Conference on Computer Vision (ICCV)<br>
	European Conference on Computer Vision (ECCV)<br>
	AAAI Conference on Artificial Intelligence<br>
	International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)<br>
	Medical Imaging with Deep Learning (MIDL)<br>
	IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)<br>
	IEEE Transactions on Medical Imaging (TMI-Gold Distinguished Reviewer) <br>
	IEEE Journal of Biomedical and Health Informatics (J-BHI) <br>
	Neurocomputing<br>
	Information Fusion<br>
	Medical Physics<br>
	</li>
<!--	
	<li>	
	<b>Memberships:</b><br>
	MICCAI Student <br>
	<p style="margin-top:3px"></p>		
	</li>
-->
</ul>


<h2>Teaching</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> 2022-2023</td><td>Fall</td><td>Big Data in Healthcare (TA, BMEG 3103)</td>
			<td> 2021-2022</td><td>Spring</td><td>Big Data in Healthcare (TA, BMEG 3103)</td>
		</tr>
	</tbody>
</table>

<h2>Misc.</h2>
<p>
Curiosity drives my research, also my life. I pursue credo of "Work Smart, Play Hard", where I enjoy traveling (all over China, 20+ countries [<a href="https://space.bilibili.com/399165010">Vlogs</a>]), <a href="https://www.bilibili.com/video/BV1at4y1M74d">surfskate</a>, snowboard, Frisbee, SCUBA diving (PADI), <a href="https://www.bilibili.com/video/BV1BU4y197Vw">(wake-)surfing</a>, non-convex gradient ascent (hiking), cocktail and jazz blues. I spent some of my vacations on volunteering, e.g., English teaching in Cambodia and protecting animals in Thailand, Indonesia and Nepal. 
</p>
<!--
<h2>Some of My Friends</h2>&nbsp 
	<a href="http://appsrv.cse.cuhk.edu.hk/~xuli/">Li Xu</a>,&nbsp 
<p style="margin-top:3px"></p>
-->


<div id="footer">
	<div id="footer-text"></div>
</div>
	<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=777777&w=487&t=tt&d=xeJu_Kwek6AfO5eDCKFQ1iDWjzFQPLT_dNcYY3WLmrY&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=5b1717'></script>
	<p><center> &copy; Jack Xu </center></p>


</div>
</body></html>
